physics:
    forward_operator: fft2(centered=False)
    backward_operator: ifft2(centered=False)
training:
    datasets:
        # Two datasets, only difference is the shape, so the data can be collated for larger batches
        -   name: CalgaryCampinas
            filenames_lists:
                - ../../lists/train/12x218x170_train.lst
            transforms:
                cropping:
                    crop: null
                sensitivity_map_estimation:
                    estimate_sensitivity_maps: true  # Estimate the sensitivity map on the ACS
                normalization:
                    scaling_key: masked_kspace  # Compute the image normalization based on the masked_kspace maximum
                masking:
                    name: CalgaryCampinas
                    accelerations: [5, 10]
            crop_outer_slices: true
        -   name: CalgaryCampinas
            filenames_lists:
                - ../../lists/train/12x218x180_train.lst
            transforms:
                cropping:
                    crop: null
                sensitivity_map_estimation:
                    estimate_sensitivity_maps: true  # Estimate the sensitivity map on the ACS
                normalization:
                    scaling_key: masked_kspace # Compute the image normalization based on the masked_kspace maximum
                masking:
                    name: CalgaryCampinas
                    accelerations: [5, 10]
            crop_outer_slices: true
    batch_size: 2  # This is the batch size per GPU!
    optimizer: Adam
    lr: 0.0005
    weight_decay: 0.0
    lr_step_size: 20000
    lr_gamma: 0.2
    lr_warmup_iter: 1000
    num_iterations: 500000
    gradient_steps: 1
    gradient_clipping: 0.0
    gradient_debug: false
    checkpointer:
        checkpoint_steps: 1000
    validation_steps: 1000
    loss:
        crop: null
        losses:
            -   function: l1_loss
                multiplier: 1.0
            -   function: ssim_loss
                multiplier: 1.0
validation:
    datasets:
        # Twice the same dataset but a different acceleration factor
        -   name: CalgaryCampinas
            filenames_lists:
                - ../../lists/val/12x218x170_val.lst
                - ../../lists/val/12x218x180_val.lst
            transforms:
                cropping:
                    crop: null
                sensitivity_map_estimation:
                    estimate_sensitivity_maps: true  # Estimate the sensitivity map on the ACS
                normalization:
                    scaling_key: masked_kspace
                masking:
                    name: CalgaryCampinas
                    accelerations: [5]
            crop_outer_slices: true
            text_description: 5x  # Description for logging
        -   name: CalgaryCampinas
            filenames_lists:
                - ../../lists/val/12x218x170_val.lst
                - ../../lists/val/12x218x180_val.lst
            transforms:
                cropping:
                    crop: null
                sensitivity_map_estimation:
                    estimate_sensitivity_maps: true  # Estimate the sensitivity map on the ACS
                normalization:
                    scaling_key: masked_kspace
                masking:
                    name: CalgaryCampinas
                    accelerations: [10]
            crop_outer_slices: true
            text_description: 10x  # Description for logging
    crop: null  # This sets the cropping for the DoIterationOutput
    metrics:  # These are obtained from direct.functionals
        - calgary_campinas_psnr
        - calgary_campinas_ssim
        - fastmri_nmse
model:
    model_name: recurrentvarnet.recurrentvarnet.RecurrentVarNet
    num_steps: 11
    recurrent_hidden_channels: 128
    recurrent_num_layers: 3
    initializer_initialization: sense
    learned_initializer: true
    initializer_channels: [32, 32, 64, 64]
    initializer_dilations: [1, 1, 2, 4]
    initializer_multiscale: 3
additional_models:
    sensitivity_model:
        model_name: unet.unet_2d.UnetModel2d
        in_channels: 2
        out_channels: 2
        num_filters: 8
        num_pool_layers: 4
        dropout_probability: 0.0
logging:
    tensorboard:
        num_images: 4
inference:
    batch_size: 8
    dataset:
        name: CalgaryCampinas
        transforms:
            cropping:
                crop: null
            sensitivity_map_estimation:
                estimate_sensitivity_maps: true  # Estimate the sensitivity map on the ACS
            normalization:
                scaling_key: masked_kspace
            masking:
                name: CalgaryCampinas
                accelerations: [ 5 ]
        crop_outer_slices: true
        text_description: inference_5x  # Description for logging
